# Liheci HFST Analysis Pipeline

## Overview

This pipeline uses a two-stage HFST approach to recognize and validate Chinese separable verbs (离合词) in natural text.

## Pipeline Architecture

```
Input: Test Sentences (data/test_sentences.txt)
    ↓
┌─────────────────────────────────────────────────────────────┐
│ Stage 1: WHOLE/SPLIT Recognition                            │
│ Script: 03.liheci_run_hfst.py                               │
│ FST: liheci_split.analyser.hfst (131 lemmas, 663 states)   │
├─────────────────────────────────────────────────────────────┤
│ Generated by: 01.generate_liheci_split_xfst.py             │
│                                                              │
│ Recognizes:                                                  │
│   ├─ WHOLE: contiguous form (睡觉)                          │
│   └─ SPLIT: inserted form (睡了一觉, 睡一个好觉)            │
│                                                              │
│ Pattern: ?* A [Insertion] B ?*                              │
│   where [Insertion] can be:                                 │
│     - Aspect markers: 了, 过, 着                            │
│     - Quantifiers: 一, 两, 一个, 三次, etc.                 │
│     - Modifiers: 个, 好, 完, etc.                           │
│                                                              │
│ Output: outputs/liheci_hfst_outputs.tsv (328 rows)         │
│         outputs/liheci_hfst_run.log                         │
│ TSV Columns: sent_id, gold_stem, gold_label, error_type,   │
│              sentence, lemma, type_tag, shape, hfst_analysis│
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│ Stage 2: REDUP Validation                                   │
│ Script: 04.liheci_validate_redup_hfst.py                    │
│ FST: liheci_redup.analyser.hfst (55 AAB lemmas, 225 states)│
├─────────────────────────────────────────────────────────────┤
│ Generated by: 02.generate_liheci_redup_xfst.py             │
│                                                              │
│ Process:                                                     │
│ 1. Read Stage 1 output (325 rows)                          │
│ 2. Deduplicate by (sent_id, lemma, shape) → 313 rows       │
│ 3. Identify WHOLE+SPLIT cooccurrence → 124 potential REDUP │
│ 4. Run sentences through REDUP FST                         │
│ 5. Validate AAB patterns:                                   │
│      ├─ AAB: 散散步                                         │
│      ├─ A一AB: 散一散步                                     │
│      └─ A了AB: 散了散步                                     │
│ 6. Filter out invalid reduplications                        │
│                                                              │
│ Results:                                                     │
│   ├─ Valid REDUP: 18 lemmas                                │
│   ├─ Invalid REDUP: 90 rows filtered                       │
│   └─ Non-REDUP: 190 rows preserved                         │
│                                                              │
│ Output: outputs/liheci_hfst_outputs.tsv (208 rows)         │
│         outputs/liheci_redup_validation.log                 │
└─────────────────────────────────────────────────────────────┘
    ↓
Current Results: 208 valid liheci recognitions
    ├─ 190 non-reduplication cases (WHOLE or SPLIT)
    └─ 18 valid reduplication cases (REDUP)
    ↓
┌─────────────────────────────────────────────────────────────┐
│ Stage 3: Insertion Analysis & Confidence Scoring (WFST)    │
│ Script: 05.stage3_insertion_analysis.py                    │
│ FST: liheci_insertion_classifier.analyser.hfst             │
├─────────────────────────────────────────────────────────────┤
│ Generated by: scripts/03_generate_insertion_wfst.py        │
│                                                              │
│ WFST Weighted Recognition:                                  │
│   Use Tropical Semiring (lower weight = higher confidence) │
│                                                              │
│ Insertion Types with Weights:                               │
│   ├─ Aspect markers (了/过/着) → 0.05 (highest confidence)│
│   ├─ Aspect + Quantifier (了一个) → 0.08                  │
│   ├─ Quantifier only (一个/三次) → 0.15                   │
│   ├─ Pronoun insertion (我/你/他) → 0.20                  │
│   ├─ Result complement (完/好/到) → 0.25                  │
│   ├─ Modifier + Quant (好几次) → 0.18                     │
│   ├─ Demonstrative (这个/那次) → 0.30                     │
│   └─ Unknown/Complex → 0.50 (low confidence)               │
│                                                              │
│ Special Patterns:                                            │
│   ├─ REDUP forms → 0.10 (pre-validated, high confidence)  │
│   ├─ WHOLE forms → 0.60 (needs semantic validation)       │
│   └─ Empty insertion → 0.70 (suspicious)                   │
│                                                              │
│ Process:                                                     │
│ 1. Extract insertion content from SPLIT cases               │
│ 2. Run insertion through WFST classifier                    │
│ 3. Get best path weight as confidence score                 │
│ 4. Annotate with insertion_type and confidence              │
│ 5. Rank results by confidence                               │
│                                                              │
│ Output Columns:                                              │
│   [existing columns] + insertion + insertion_type + conf    │
│                                                              │
│ Output: outputs/liheci_with_insertion_analysis.tsv         │
│         outputs/liheci_insertion_analysis.log               │
└─────────────────────────────────────────────────────────────┘
    ↓
Candidates ranked by confidence (208 rows with scores)
    ↓
[Stage 4] Threshold-based Filtering (Optional)
    ├─ Filter candidates with confidence < 0.40
    ├─ Manual review for 0.40-0.60 range
    └─ Auto-accept confidence ≥ 0.60
    ↓
High-confidence candidates (~150-180 rows)
    ↓
[Stage 5] Python Semantic Validation (Future)
    ├─ HanLP POS tagging verification
    ├─ Transitivity and PP requirement checking
    ├─ Semantic role analysis for pronoun insertion
    └─ Cross-sentence context analysis
    ↓
Final validated results

## File Descriptions

### Data Files
- `data/liheci_lexicon.csv` - Main lexicon (131 lemmas)
  - Contains: Lemma, A, B, Type, Pinyin, Definition, RedupPattern
  - 55 lemmas marked as RedupPattern='AAB'
- `data/test_sentences.txt` - Test sentences with gold annotations

### Stage 1: WHOLE/SPLIT Recognition
- `scripts/01.generate_liheci_split_xfst.py` - Generates XFST rules for Stage 1
- `scripts/hfst_files/liheci_split.xfst` - Generated XFST file (663 states)
- `scripts/hfst_files/liheci_split.analyser.hfst` - Compiled HFST analyser
- `scripts/hfst_files/liheci_split.generator.hfst` - Compiled HFST generator
- `scripts/03.stage1_split_whole_recognition.py` - Stage 1 runner script

### Stage 2: REDUP Validation
- `scripts/02.generate_liheci_redup_xfst.py` - Generates XFST rules for REDUP patterns
- `scripts/hfst_files/liheci_redup.xfst` - Generated XFST file (225 states)
- `scripts/hfst_files/liheci_redup.analyser.hfst` - Compiled HFST analyser
- `scripts/hfst_files/liheci_redup.generator.hfst` - Compiled HFST generator
- `scripts/04.stage2_redup_recognition.py` - Stage 2 validator script

### Stage 3: Insertion Analysis (WFST)
- `scripts/03_generate_insertion_wfst.py` - Generates weighted XFST for insertion types
- `scripts/hfst_files/liheci_insertion_classifier.xfst` - WFST with confidence weights
- `scripts/hfst_files/liheci_insertion_classifier.analyser.hfst` - Compiled weighted analyser
- `scripts/05.stage3_insertion_analysis.py` - Stage 3 insertion analyzer

### Output Files
- `outputs/liheci_hfst_outputs.tsv` - Stage 1→2 final output (208 rows)
- `outputs/liheci_hfst_run.log` - Stage 1 execution log
- `outputs/liheci_redup_validation.log` - Stage 2 validation log
- `outputs/liheci_with_insertion_analysis.tsv` - Stage 3 output with confidence scores
- `outputs/liheci_insertion_analysis.log` - Stage 3 analysis log

## Valid REDUP Lemmas (18 total)

散步, 见面, 聊天, 睡觉, 把脉, 洗澡, 鼓掌, 敲门, 放假, 开会, 加班, 输液, 看病, 游泳, 排队, 散心, 请客, (1 more from latest run)

## Invalid REDUP Lemmas Filtered (45 total)

结婚, 离婚, 订婚, 分手, 放心, 担心, 灰心, 操心, 动心, 下课, 请假, 考试, 留学, 辞职, 生病, 住院, 鞠躬, 敬礼, 站岗, 受罪, 出院, 回家, 签名, 戒烟, 受伤, 扫兴, 接吻, 开枪, 受骗, 挨批, 干杯, 退休, 出事, 提醒, 出恭, 学习, 慷慨, 幽默, 滑稽, 军训, 体检, 同学, 告状, 请客

## Technical Details

### XFST Generation
Both Stage 1 and Stage 2 use the same technical approach:
1. Python script reads lexicon CSV
2. Generates XFST rules with proper formatting:
   - Chinese characters must be space-separated
   - Comments use `!` not `#`
   - Generator saved first, then inverted to analyser
3. Compile with `hfst-xfst -F` (OpenFST tropical semiring)

### HFST Lookup
- Command: `hfst-lookup <fst_file>`
- Input: Sentences (one per line)
- Output: TAB-separated format: `input\tanalysis\tweight`
- Parse analysis tags: `睡觉+Lemma+Verb-Object+SPLIT`
