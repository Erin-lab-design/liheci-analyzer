! liheci_split_transducer.xfst
! 目标：句子 → lemma-ID 的 transducer：
!   输入：整句字符串
!   输出：LEMMA_TAN_LIAN_AI_SPLIT / LEMMA_CHI_FAN_SPLIT 等

! -----------------------------
! 1) 符号集合
! -----------------------------
define Punct   [， | 。 | 、 | ！ | ？ | ： | ； | "，" | "。" | "," | "." | "!" | "?"];
define AnyChar [?];
define LegalIns [AnyChar - Punct];

! -----------------------------
! 2) 每个 lemma 的 sentence pattern（下层）
! -----------------------------
define SentTanLianAi  ?* 谈 LegalIns* 恋 爱 ?* ;
define SentChiFan     ?* 吃 LegalIns* 饭 ?* ;

! 如果你想把连续的“谈恋爱/吃饭”也纳入，可以改成：
! define SentTanLianAi  (?* 谈 LegalIns* 恋 爱 ?* | ?* 谈恋爱 ?* );
! define SentChiFan     (?* 吃 LegalIns* 饭 ?* | ?* 吃饭 ?* );

! -----------------------------
! 3) 为每个 lemma 建一个单独的 transducer
!    上层是 ASCII ID， 下层是句子正则
! -----------------------------
define T_TanLianAi  "LEMMA_TAN_LIAN_AI_SPLIT" : SentTanLianAi ;
define T_ChiFan     "LEMMA_CHI_FAN_SPLIT"     : SentChiFan ;

! -----------------------------
! 4) 组合成一个总网络
! -----------------------------
regex T_TanLianAi | T_ChiFan ;

! 此时栈顶是 generator：
!   上层：LEMMA_... ID
!   下层：满足对应 Split 模式的整句

! -----------------------------
! 5) 保存 generator，反转成 analyser
! -----------------------------
save stack liheci_split.generator.hfst

invert net

save stack liheci_split.analyser.hfst

quit
