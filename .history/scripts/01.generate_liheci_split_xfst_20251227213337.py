#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
generate_liheci_split_xfst_v3.py

从 liheci_lexicon.csv 自动生成：
liheci_split.xfst

编译：
    hfst-xfst < liheci_split.xfst

生成：
    liheci_split.generator.hfst   (lemma-tag → 句子)
    liheci_split.analyser.hfst    (句子 → lemma-tag)

输出标签示例：
    散心+Lemma+Verb-Object+WHOLE
    散心+Lemma+Verb-Object+SPLIT
    散心+Lemma+Verb-Object+SPLIT+REDUP
"""

import csv
from pathlib import Path

INPUT_CSV = "data/liheci_lexicon.csv"
OUTPUT_XFST = "liheci_split.xfst"


def map_type_tag(type_str: str) -> str:
    """
    把 CSV 里的 Type 映射到 HFST 用的类型标签（无空格）。
    保留原本语义：Verb-Object, Pseudo V-O, Modifier-Head, Simplex Word
    """
    t = (type_str or "").strip()
    if not t:
        return "UnknownType"
    # 去掉空格即可，dash 保留
    return t.replace(" ", "")


def has_redup(notes: str) -> bool:
    """
    Notes 里含 'AAB' 就当作这个 lemma 支持重叠形式
    （比如 散散心(AAB)，握了一下手(AAB) 等）
    """
    if not notes:
        return False
    return "AAB" in notes


def chars_with_space(s: str) -> str:
    """把字符串拆成单字符并用空格隔开，供 xfst 正则使用。"""
    s = (s or "").strip()
    if not s:
        return ""
    return " ".join(list(s))


def main():
    input_path = Path(INPUT_CSV)
    if not input_path.exists():
        raise SystemExit(f"ERROR: 找不到 {INPUT_CSV}，请确认文件名和路径。")

    rows = []
    with input_path.open(encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            lemma = (row.get("Lemma") or "").strip()
            head = (row.get("A") or "").strip()
            tail = (row.get("B") or "").strip()
            # 跳过残缺行（比如单独一行 'c'）
            if not lemma or not head or not tail:
                continue
            rows.append(row)

    lines = []

    # =======================
    # 1) 公共定义
    # =======================
    lines.append("! Auto-generated by generate_liheci_split_xfst_v3.py")
    lines.append("! Sentence-level Liheci WHOLE / SPLIT / REDUP recognizer")
    lines.append("")

    lines.append("! 1) 符号集合")
    lines.append(
        'define Punct [， | 。 | 、 | ！ | ？ | ： | ； | "，" | "。" | "," | "." | "!" | "?"];'
    )
    lines.append("define AnyChar [?];")
    lines.append("define LegalIns [AnyChar - Punct];")
    # A_XAB 中间的 X，目前先支持 "一" 和 "了"
    lines.append("define RedupMid [一 | 了];")
    lines.append("")

    all_transducer_names = []

    # =======================
    # 2) 每个 lemma 生成 pattern + transducer
    # =======================
    for idx, row in enumerate(rows, start=1):
        lemma = (row.get("Lemma") or "").strip()
        head = (row.get("A") or "").strip()
        tail = (row.get("B") or "").strip()
        type_str = (row.get("Type") or "").strip()
        notes = (row.get("Notes") or "").strip()

        type_tag = map_type_tag(type_str)

        head_chars = chars_with_space(head)
        tail_chars = chars_with_space(tail)
        if not head_chars or not tail_chars:
            continue

        base = f"L{idx:03d}"  # L001, L002, ...

        # upper-side 标签
        # 例：散步+Lemma+Verb-Object+WHOLE / +SPLIT / +SPLIT+REDUP
        whole_upper = f"{lemma}+Lemma+{type_tag}+WHOLE"
        split_upper = f"{lemma}+Lemma+{type_tag}+SPLIT"
        redup_upper = f"{lemma}+Lemma+{type_tag}+SPLIT+REDUP"

        whole_pat_name = f"{base}WholePat"
        split_pat_name = f"{base}SplitPat"
        whole_only_pat_name = f"{base}WholeOnlyPat"
        split_only_pat_name = f"{base}SplitOnlyPat"
        whole_tr_name = f"{base}Whole"
        split_tr_name = f"{base}Split"

        lines.append(f"! === {lemma} (Type={type_str}) ===")

        # --- 基本 WHOLE / SPLIT 模式 ---
        lines.append(f"define {whole_pat_name} ?* {head_chars} {tail_chars} ?* ;")
        # 至少一个插入：Head LegalIns LegalIns* Tail
        lines.append(
            f"define {split_pat_name} ?* {head_chars} LegalIns LegalIns* {tail_chars} ?* ;"
        )

        transducers_for_this = []

        if has_redup(notes):
            # 对有重叠的 lemma，定义 RedupPat：
            # - AAB: H H T
            # - A_XAB: H RedupMid H T (X ∈ {一, 了})
            redup_pat_name = f"{base}RedupPat"
            redup_tr_name = f"{base}Redup"
            lines.append(
                f"define {redup_pat_name} "
                f"(?* {head_chars} {head_chars} {tail_chars} ?* "
                f"| ?* {head_chars} RedupMid {head_chars} {tail_chars} ?* ) ;"
            )

            # WHOLE / SPLIT 都要排除掉重叠的那些句子
            lines.append(
                f"define {whole_only_pat_name} {whole_pat_name} - {redup_pat_name} ;"
            )
            lines.append(
                f"define {split_only_pat_name} {split_pat_name} - {redup_pat_name} ;"
            )

            # 绑定 transducer
            lines.append(f'define {whole_tr_name} "{whole_upper}" : {whole_only_pat_name} ;')
            lines.append(f'define {split_tr_name} "{split_upper}" : {split_only_pat_name} ;')
            lines.append(f'define {redup_tr_name} "{redup_upper}" : {redup_pat_name} ;')

            transducers_for_this.extend([whole_tr_name, split_tr_name, redup_tr_name])
        else:
            # 对没有重叠的 lemma，直接用 WholePat / SplitPat
            lines.append(f"define {whole_only_pat_name} {whole_pat_name} ;")
            lines.append(f"define {split_only_pat_name} {split_pat_name} ;")

            lines.append(f'define {whole_tr_name} "{whole_upper}" : {whole_only_pat_name} ;')
            lines.append(f'define {split_tr_name} "{split_upper}" : {split_only_pat_name} ;')

            transducers_for_this.extend([whole_tr_name, split_tr_name])

        lines.append("")

        all_transducer_names.extend(transducers_for_this)

    # =======================
    # 3) union + 保存
    # =======================
    lines.append("! 组合所有 lemma 的 transducer")
    if all_transducer_names:
        union_expr = " | ".join(all_transducer_names)
        lines.append("regex " + union_expr + " ;")
    else:
        lines.append("regex [] ; ! 没有 lemma，空语言")

    lines.append("")
    lines.append("! 现在栈顶是 generator：")
    lines.append("! 上层：<Lemma>+Lemma+TypeTag+FORM(+REDUP?)")
    lines.append("! 下层：满足对应模式的整句")
    lines.append("save stack liheci_split.generator.hfst")
    lines.append("")

    lines.append("invert net")
    lines.append("save stack liheci_split.analyser.hfst")
    lines.append("")

    lines.append("quit")
    lines.append("")

    Path(OUTPUT_XFST).write_text("\n".join(lines), encoding="utf-8")
    print(f"[OK] 已生成 {OUTPUT_XFST}，共 {len(rows)} 个 lemma")


if __name__ == "__main__":
    main()
